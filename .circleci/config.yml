version: 2.1

orbs:
  dagster-pipelines-orb: nextail/dagster-pipelines-orb@5.0.1

parameters:
  custom_service_account:
    type: boolean
    default: true
    description: "Define if our project uses its own service account (true) or by default (false)."
  use_secrets:
    type: boolean
    default: true
    description: "Whether our project uses secrets (a secret provider class must exist)"
  use_parameters:
    type: boolean
    default: false
    description: "Whether our project uses parameters (a parameter secret provider class must exist)"
  use_datadog_tracer:
      type: boolean
      default: false
      description: Provides access to host's datadog socket, so apm traces can be sent through using default configuration.
  module_name:
    type: string
    default: nx_dbt.dagster
    description: "Python module containing the target Dagster Definitions"
  project_name:
    type: string
    default: default
    description: "By default all projects will be named as {github-repo-name}-default"
  branch_deployment:
    type: string
    default: /deploy\/.*/
    description: "Regex for branch deployments. For example: deploy/**"
  code_location_resource_limit_memory:
    type: string
    description: Kubernetes Limits - the container can never consume more than the CPU amount indicated.
    default: 256Mi
  code_location_grpc_max_workers:
    type: integer
    description: Maximum number of workers available on the code server.
    default: 8
  job_run_resource_limit_cpu:
    type: string
    description: Kubernetes Limits - the container can never consume more than the memory amount indicated.
    default: 500m
  job_run_resource_limit_memory:
    type: string
    description: Kubernetes Limits - the container can never consume more than the CPU amount indicated.
    default: 1Gi
  GHA_Actor:
    type: string
    description: Integration with Github Actions
    default: ""
  GHA_Action:
    type: string
    description: Integration with Github Actions
    default: ""
  GHA_Event:
    type: string
    description: Integration with Github Actions
    default: ""
  GHA_Meta:
    type: string
    description: Integration with Github Actions
    default: ""

workflows:
  # This workflow is set to be conditionally triggered, only when
  # the GitHub Action is triggered .
  external-trigger-open:
    when:
      and:
        - equal: [OPEN, << pipeline.parameters.GHA_Meta >>]
    jobs:
      # check secrets on code
      - dagster-pipelines-orb/check-secrets

      # run make test
      - dagster-pipelines-orb/tests:
          context: org-global

      # build-and-deploy for branch deployment environment
      - dagster-pipelines-orb/build-and-deploy-branch:
          actor_op: <<pipeline.parameters.GHA_Actor>>
          trigger_op: <<pipeline.parameters.GHA_Meta>>
          custom_service_account: <<pipeline.parameters.custom_service_account>>
          use_secrets: <<pipeline.parameters.use_secrets>>
          use_parameters: <<pipeline.parameters.use_parameters>>
          use_datadog_tracer: <<pipeline.parameters.use_datadog_tracer>>
          module_name: <<pipeline.parameters.module_name>>
          project_name: <<pipeline.parameters.project_name>>
          code_location_resource_limit_memory: <<pipeline.parameters.code_location_resource_limit_memory>>
          code_location_grpc_max_workers: <<pipeline.parameters.code_location_grpc_max_workers>>
          job_run_resource_limit_cpu: <<pipeline.parameters.job_run_resource_limit_cpu>>
          job_run_resource_limit_memory: <<pipeline.parameters.job_run_resource_limit_memory>>
          requires:
            - dagster-pipelines-orb/check-secrets
            - dagster-pipelines-orb/tests
          context: org-global

  # This workflow is set to be conditionally triggered, only when
  # the GitHub Action is triggered.
  external-trigger-close-or-merge:
    when:
      or:
        - equal: [CLOSED, <<pipeline.parameters.GHA_Meta>>]
        - matches:
            {
              pattern: <<pipeline.parameters.branch_deployment>>,
              value: <<pipeline.parameters.GHA_Meta>>,
            }
    jobs:
      # build-and-deploy for branch deployment environment
      - dagster-pipelines-orb/build-and-deploy-branch:
          actor_op: <<pipeline.parameters.GHA_Actor>>
          trigger_op: <<pipeline.parameters.GHA_Meta>>
          custom_service_account: <<pipeline.parameters.custom_service_account>>
          use_secrets: <<pipeline.parameters.use_secrets>>
          use_parameters: <<pipeline.parameters.use_parameters>>
          use_datadog_tracer: <<pipeline.parameters.use_datadog_tracer>>
          module_name: <<pipeline.parameters.module_name>>
          project_name: <<pipeline.parameters.project_name>>
          code_location_resource_limit_memory: <<pipeline.parameters.code_location_resource_limit_memory>>
          code_location_grpc_max_workers: <<pipeline.parameters.code_location_grpc_max_workers>>
          job_run_resource_limit_cpu: <<pipeline.parameters.job_run_resource_limit_cpu>>
          job_run_resource_limit_memory: <<pipeline.parameters.job_run_resource_limit_memory>>
          context: org-global

  infrastructure:
    when:
      and:
        - not: <<pipeline.parameters.GHA_Action>>
    jobs:
      # internal tool to deploy our Helm chart
      - dagster-pipelines-orb/service-account-sandbox:
          context: org-global
          filters:
            branches:
              only:
                - sandbox

      # internal tool to deploy our Helm chart
      - dagster-pipelines-orb/service-account-production:
          context: org-global
          filters:
            branches:
              only:
                - main

  build-and-deploy:
    when:
      and:
        - not: <<pipeline.parameters.GHA_Action>>
    jobs:
      # check secrets on code
      - dagster-pipelines-orb/check-secrets:
          filters:
            branches:
              ignore:
                - <<pipeline.parameters.branch_deployment>>

      # pre-commit
      - dagster-pipelines-orb/pre-commit:
          python-executor: dagster-pipelines-orb/py3-11-executor
          filters:
            branches:
              ignore:
                - sandbox
                - <<pipeline.parameters.branch_deployment>>

      # run make test
      - dagster-pipelines-orb/tests:
          context: org-global
          filters:
            branches:
              ignore:
                - <<pipeline.parameters.branch_deployment>>

      # build-and-deploy for sandbox dagster environment
      - dagster-pipelines-orb/build-and-deploy-sandbox:
          custom_service_account: <<pipeline.parameters.custom_service_account>>
          use_secrets: <<pipeline.parameters.use_secrets>>
          use_parameters: <<pipeline.parameters.use_parameters>>
          use_datadog_tracer: <<pipeline.parameters.use_datadog_tracer>>
          module_name: <<pipeline.parameters.module_name>>
          project_name: <<pipeline.parameters.project_name>>
          code_location_resource_limit_memory: <<pipeline.parameters.code_location_resource_limit_memory>>
          code_location_grpc_max_workers: <<pipeline.parameters.code_location_grpc_max_workers>>
          job_run_resource_limit_cpu: <<pipeline.parameters.job_run_resource_limit_cpu>>
          job_run_resource_limit_memory: <<pipeline.parameters.job_run_resource_limit_memory>>
          requires:
            - dagster-pipelines-orb/check-secrets
            - dagster-pipelines-orb/tests
          context: org-global
          filters:
            branches:
              only:
                - sandbox

      # # build-and-deploy for prod dagster environment
      # # uncomment to deploy to production
      # - dagster-pipelines-orb/build-and-deploy-production:
      #     custom_service_account: <<pipeline.parameters.custom_service_account>>
      #     use_secrets: <<pipeline.parameters.use_secrets>>
      #     use_parameters: <<pipeline.parameters.use_parameters>>
      #     use_datadog_tracer: <<pipeline.parameters.use_datadog_tracer>>
      #     module_name: <<pipeline.parameters.module_name>>
      #     project_name: <<pipeline.parameters.project_name>>
      #     code_location_resource_limit_memory: <<pipeline.parameters.code_location_resource_limit_memory>>
      #     code_location_grpc_max_workers: <<pipeline.parameters.code_location_grpc_max_workers>>
      #     job_run_resource_limit_cpu: <<pipeline.parameters.job_run_resource_limit_cpu>>
      #     job_run_resource_limit_memory: <<pipeline.parameters.job_run_resource_limit_memory>>
      #     requires:
      #       - dagster-pipelines-orb/pre-commit
      #       - dagster-pipelines-orb/check-secrets
      #       - dagster-pipelines-orb/tests
      #     context: org-global
      #     filters:
      #       branches:
      #         only:
      #           - main
